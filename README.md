# The Complete MLOps Study Roadmap: 
## 1. The Foundations: 
- ### Python.
- ### SQL.
- ### Mathematics. 
## 2. Machine Learning Algorithms and Libraries:
   ### As an MLOps engineer, your day-to-day tasks will revolve around Machine Learning algorithms, therefore it is important for you to understand the models you are working with in-depth. You will also need to know the libraries and frameworks to succeed in your role. 
   
## 3. Databases: 
   ### Taking the aspect of a Data Engineers role, Databases and their management systems are an important element to an MLOps Engineers roles and responsibilities. In order for you to maintain the machine learning systems in a reliable and efficient way, you will need databases to help you with that.
   - ### SQLite.
   - ### MySQL. 
   - ### PostgreSQL.
   
 ## 4. Model Deployment: 
  ### As an MLOps Engineer, you will need to learn how to deploy your models. Large companies typically use cloud platforms to host their applications, such as AWS,         GCP, and Microsoft Azure. So it is highly likely that you will also be doing the same, therefore I would highly recommend that you have a good understanding of each       of these, as you will most certainly be using it as an MLOps Engineer. 
 
 ## 5. Experiment Tracking:
 ### For some professionals who work with data, their end goal is to achieve model deployment. However, as an MLOps Engineer, experiment tracking is vital. Experiment tracking allows us to manage all the experiments along with their components, such as parameters, metrics, and more. This makes it easier for us to organize the component of each experiment, reproduce past results and log everything. 

### As an MLOps engineer, you should know about the different tools you can use to track your experiments. I will list the most popular ones:

- MLFlow.
- Comet ML.
- Neptune.
- Weights and Biases.
- TensorBoard.

## 6. Metadata Management
### Metadata is data about data, and the management of this type of data can help you gain a better understanding, group, and sort the data for other uses. Producing metadata from a model can be used to train parameters, evaluate metrics, test pipeline outputs.

## 7. Data and Pipeline Versioning:
### Data versioning is the storage of different versions of data that have been created over time. There are different reasons why the data changes over time, such as data scientists testing to see if they can increase the efficiency of an ML model or the flow of information. The advantage and need for data versioning help from a business perspective by enabling consumers to be aware if a newer version of the dataset is available.

### Below is a list of popular tools used for data versioning:

- DAGsHub
- DVC
- Pachyderm
- lakeFS

## 8. Model monitoring:
 ### The model monitoring stage comes after model deployment and is the process of exactly what it says - monitoring the model. You want to be looking out for model degradation, data drift, and others to ensure your model is at a good performance level. 
